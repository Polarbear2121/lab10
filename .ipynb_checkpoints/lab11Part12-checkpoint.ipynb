{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90570, 2627)\n",
      "(90570,)\n",
      "(9430, 2627)\n",
      "(9430,)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "\n",
    "num_users = 945\n",
    "num_movies = 1682\n",
    "num_features = num_users + num_movies\n",
    "num_ratings_train = 90570\n",
    "num_ratings_test = 9430\n",
    "\n",
    "\n",
    "#Function to upload the datasets\n",
    "def loadDataset(filename, lines, columns):\n",
    "# Sparse Matric    \n",
    "    X = scipy.sparse.lil_matrix((lines, columns)).astype('float32')\n",
    "#  Y is the movie rating \n",
    "    Y = []  \n",
    "    line = 0\n",
    "    with open (filename, 'r') as f:\n",
    "        samples = csv.reader(f, delimiter='\\t')\n",
    "        for userId, movieId, rating, timestap in samples:\n",
    "            X[line, int(userId)] = 1\n",
    "            X[line, int(num_users) + int(movieId) -1] = 1\n",
    "            Y.append(int(rating))\n",
    "            line=line+1  #index for loop\n",
    "\n",
    "    Y=np.array(Y).astype('float32')\n",
    "    return X, Y\n",
    "\n",
    "#Split data for trainning and test\n",
    "X_train, Y_train = loadDataset('/home/ec2-user/SageMaker/database/ml-100k/ua.base.shuffled', num_ratings_train, num_features)\n",
    "X_test, Y_test = loadDataset('/home/ec2-user/SageMaker/database/ml-100k/ua.test', num_ratings_test, num_features)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.BytesIO object at 0x7f0058c84fc0>\n",
      "Wrote dataset: sagemaker-us-east-1-027893685092/fm-movielens/train/train.protobuf\n",
      "<_io.BytesIO object at 0x7f0058c84fc0>\n",
      "Wrote dataset: sagemaker-us-east-1-027893685092/fm-movielens/test/test.protobuf\n",
      "s3://sagemaker-us-east-1-027893685092/fm-movielens/train/train.protobuf\n",
      "s3://sagemaker-us-east-1-027893685092/fm-movielens/test/test.protobuf\n",
      "Output: s3://sagemaker-us-east-1-027893685092/fm-movielens/output\n"
     ]
    }
   ],
   "source": [
    "import io,boto3\n",
    "import sagemaker.amazon.common as smac\n",
    "import sagemaker\n",
    "\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = 'fm-movielens'\n",
    "train_key      = 'train.protobuf'\n",
    "train_prefix   = '{}/{}'.format(prefix, 'train')\n",
    "test_key       = 'test.protobuf'\n",
    "test_prefix    = '{}/{}'.format(prefix, 'test')\n",
    "output_prefix  = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "\n",
    "\n",
    "# Function that converts a dataset to the RecordIO-wrapped protobuf and uploads it to an S3 bucket \n",
    "def writeDatasetToProtobuf(X, Y, bucket, prefix, key):\n",
    "\n",
    "    buf = io.BytesIO()  # in memory binary stream\n",
    "    smac.write_spmatrix_to_sparse_tensor(buf, X, Y)  # sparse matrix\n",
    "    buf.seek(0)\n",
    "    print(buf)\n",
    "    obj = '{}/{}'.format(prefix, key)\n",
    "    boto3.resource('s3').Bucket(bucket).Object(obj).upload_fileobj(buf)\n",
    "    print('Wrote dataset: {}/{}'.format(bucket,obj))\n",
    "    return 's3://{}/{}'.format(bucket,obj)\n",
    "    \n",
    "train_data = writeDatasetToProtobuf(X_train, Y_train, bucket, train_prefix, train_key)    \n",
    "test_data = writeDatasetToProtobuf(X_test, Y_test, bucket, test_prefix, test_key)    \n",
    "\n",
    "print(train_data)\n",
    "print(test_data)\n",
    "print('Output: {}'.format(output_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-01 00:01:18 Starting - Starting the training job...\n",
      "2020-12-01 00:01:23 Starting - Launching requested ML instances.........\n",
      "2020-12-01 00:02:54 Starting - Preparing the instances for training......\n",
      "2020-12-01 00:04:14 Downloading - Downloading input data\n",
      "2020-12-01 00:04:14 Training - Downloading the training image...\n",
      "2020-12-01 00:04:41 Training - Training image download completed. Training in progress.\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python2.7/site-packages/pandas/util/nosetester.py:13: DeprecationWarning: Importing from numpy.testing.nosetester is deprecated, import from numpy.testing instead.\n",
      "  from numpy.testing import nosetester\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:42 INFO 139969969338176] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-conf.json: {u'factors_lr': u'0.0001', u'linear_init_sigma': u'0.01', u'epochs': 1, u'_wd': u'1.0', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'factors_init_sigma': u'0.001', u'_log_level': u'info', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'linear_lr': u'0.001', u'factors_init_method': u'normal', u'_tuning_objective_metric': u'', u'bias_wd': u'0.01', u'use_linear': u'true', u'bias_lr': u'0.1', u'mini_batch_size': u'1000', u'_use_full_symbolic': u'true', u'batch_metrics_publish_interval': u'500', u'bias_init_sigma': u'0.01', u'_num_gpus': u'auto', u'_data_format': u'record', u'factors_wd': u'0.00001', u'linear_wd': u'0.001', u'_kvstore': u'auto', u'_learning_rate': u'1.0', u'_optimizer': u'adam'}\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:42 INFO 139969969338176] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'epochs': u'10', u'feature_dim': u'2627', u'mini_batch_size': u'1000', u'predictor_type': u'regressor', u'num_factors': u'64'}\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:42 INFO 139969969338176] Final configuration: {u'factors_lr': u'0.0001', u'linear_init_sigma': u'0.01', u'epochs': u'10', u'feature_dim': u'2627', u'num_factors': u'64', u'_wd': u'1.0', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'factors_init_sigma': u'0.001', u'_log_level': u'info', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'linear_lr': u'0.001', u'factors_init_method': u'normal', u'_tuning_objective_metric': u'', u'bias_wd': u'0.01', u'use_linear': u'true', u'bias_lr': u'0.1', u'mini_batch_size': u'1000', u'_use_full_symbolic': u'true', u'batch_metrics_publish_interval': u'500', u'predictor_type': u'regressor', u'bias_init_sigma': u'0.01', u'_num_gpus': u'auto', u'_data_format': u'record', u'factors_wd': u'0.00001', u'linear_wd': u'0.001', u'_kvstore': u'auto', u'_learning_rate': u'1.0', u'_optimizer': u'adam'}\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:42 WARNING 139969969338176] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:42 INFO 139969969338176] Using default worker.\u001b[0m\n",
      "\u001b[34m[2020-12-01 00:04:42.582] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[34m[2020-12-01 00:04:42.586] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 7, \"num_examples\": 1, \"num_bytes\": 64000}\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:42 INFO 139969969338176] nvidia-smi took: 0.0251548290253 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:42 INFO 139969969338176] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:42 INFO 139969969338176] [Sparse network] Building a sparse network.\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:42 INFO 139969969338176] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 35.02082824707031, \"sum\": 35.02082824707031, \"min\": 35.02082824707031}}, \"EndTime\": 1606781082.62012, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1606781082.577947}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 1000, \"sum\": 1000.0, \"min\": 1000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1000, \"sum\": 1000.0, \"min\": 1000}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1606781082.620285, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1606781082.620246}\n",
      "\u001b[0m\n",
      "\u001b[34m[00:04:42] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.203343.0/AL2012/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[34m[00:04:42] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.203343.0/AL2012/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:42 INFO 139969969338176] #quality_metric: host=algo-1, epoch=0, batch=0 train rmse <loss>=3.6836542446\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:42 INFO 139969969338176] #quality_metric: host=algo-1, epoch=0, batch=0 train mse <loss>=13.5693085937\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:42 INFO 139969969338176] #quality_metric: host=algo-1, epoch=0, batch=0 train absolute_loss <loss>=3.51305810547\u001b[0m\n",
      "\u001b[34m[2020-12-01 00:04:43.199] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 2, \"duration\": 561, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:43 INFO 139969969338176] #quality_metric: host=algo-1, epoch=0, train rmse <loss>=1.73858454725\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:43 INFO 139969969338176] #quality_metric: host=algo-1, epoch=0, train mse <loss>=3.02267622795\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:43 INFO 139969969338176] #quality_metric: host=algo-1, epoch=0, train absolute_loss <loss>=1.37939860451\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}, \"update.time\": {\"count\": 1, \"max\": 579.2019367218018, \"sum\": 579.2019367218018, \"min\": 579.2019367218018}}, \"EndTime\": 1606781083.199662, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1606781082.620189}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:43 INFO 139969969338176] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 92, \"sum\": 92.0, \"min\": 92}, \"Total Records Seen\": {\"count\": 1, \"max\": 91570, \"sum\": 91570.0, \"min\": 91570}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1606781083.199957, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 0}, \"StartTime\": 1606781082.620428}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:43 INFO 139969969338176] #throughput_metric: host=algo-1, train throughput=156250.83067 records/second\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:43 INFO 139969969338176] #quality_metric: host=algo-1, epoch=1, batch=0 train rmse <loss>=1.09916599909\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:43 INFO 139969969338176] #quality_metric: host=algo-1, epoch=1, batch=0 train mse <loss>=1.20816589355\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:43 INFO 139969969338176] #quality_metric: host=algo-1, epoch=1, batch=0 train absolute_loss <loss>=0.923756591797\u001b[0m\n",
      "\u001b[34m[2020-12-01 00:04:43.832] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 630, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:43 INFO 139969969338176] #quality_metric: host=algo-1, epoch=1, train rmse <loss>=1.13158593896\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:43 INFO 139969969338176] #quality_metric: host=algo-1, epoch=1, train mse <loss>=1.28048673726\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:43 INFO 139969969338176] #quality_metric: host=algo-1, epoch=1, train absolute_loss <loss>=0.946709640335\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 632.1170330047607, \"sum\": 632.1170330047607, \"min\": 632.1170330047607}}, \"EndTime\": 1606781083.832668, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1606781083.199742}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:43 INFO 139969969338176] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 183, \"sum\": 183.0, \"min\": 183}, \"Total Records Seen\": {\"count\": 1, \"max\": 182140, \"sum\": 182140.0, \"min\": 182140}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1606781083.832872, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 1}, \"StartTime\": 1606781083.20052}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:43 INFO 139969969338176] #throughput_metric: host=algo-1, train throughput=143202.273756 records/second\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:43 INFO 139969969338176] #quality_metric: host=algo-1, epoch=2, batch=0 train rmse <loss>=1.08281030168\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:43 INFO 139969969338176] #quality_metric: host=algo-1, epoch=2, batch=0 train mse <loss>=1.17247814941\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:43 INFO 139969969338176] #quality_metric: host=algo-1, epoch=2, batch=0 train absolute_loss <loss>=0.910402282715\u001b[0m\n",
      "\u001b[34m[2020-12-01 00:04:44.458] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 623, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:44 INFO 139969969338176] #quality_metric: host=algo-1, epoch=2, train rmse <loss>=1.11365975287\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:44 INFO 139969969338176] #quality_metric: host=algo-1, epoch=2, train mse <loss>=1.24023804516\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:44 INFO 139969969338176] #quality_metric: host=algo-1, epoch=2, train absolute_loss <loss>=0.929778292142\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 625.3290176391602, \"sum\": 625.3290176391602, \"min\": 625.3290176391602}}, \"EndTime\": 1606781084.458775, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1606781083.832741}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:44 INFO 139969969338176] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 274, \"sum\": 274.0, \"min\": 274}, \"Total Records Seen\": {\"count\": 1, \"max\": 272710, \"sum\": 272710.0, \"min\": 272710}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1606781084.458926, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 2}, \"StartTime\": 1606781083.833419}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:44 INFO 139969969338176] #throughput_metric: host=algo-1, train throughput=144762.126491 records/second\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:44 INFO 139969969338176] #quality_metric: host=algo-1, epoch=3, batch=0 train rmse <loss>=1.06394765808\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:44 INFO 139969969338176] #quality_metric: host=algo-1, epoch=3, batch=0 train mse <loss>=1.13198461914\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:44 INFO 139969969338176] #quality_metric: host=algo-1, epoch=3, batch=0 train absolute_loss <loss>=0.893418640137\u001b[0m\n",
      "\u001b[34m[2020-12-01 00:04:45.081] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 8, \"duration\": 620, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:45 INFO 139969969338176] #quality_metric: host=algo-1, epoch=3, train rmse <loss>=1.09448924776\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:45 INFO 139969969338176] #quality_metric: host=algo-1, epoch=3, train mse <loss>=1.19790671346\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:45 INFO 139969969338176] #quality_metric: host=algo-1, epoch=3, train absolute_loss <loss>=0.910700905601\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 622.5588321685791, \"sum\": 622.5588321685791, \"min\": 622.5588321685791}}, \"EndTime\": 1606781085.081956, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1606781084.458836}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:45 INFO 139969969338176] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 365, \"sum\": 365.0, \"min\": 365}, \"Total Records Seen\": {\"count\": 1, \"max\": 363280, \"sum\": 363280.0, \"min\": 363280}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}}, \"EndTime\": 1606781085.082129, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 3}, \"StartTime\": 1606781084.459369}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:45 INFO 139969969338176] #throughput_metric: host=algo-1, train throughput=145410.116626 records/second\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:45 INFO 139969969338176] #quality_metric: host=algo-1, epoch=4, batch=0 train rmse <loss>=1.04430181661\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:45 INFO 139969969338176] #quality_metric: host=algo-1, epoch=4, batch=0 train mse <loss>=1.09056628418\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:45 INFO 139969969338176] #quality_metric: host=algo-1, epoch=4, batch=0 train absolute_loss <loss>=0.87455255127\u001b[0m\n",
      "\u001b[34m[2020-12-01 00:04:45.625] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 10, \"duration\": 541, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:45 INFO 139969969338176] #quality_metric: host=algo-1, epoch=4, train rmse <loss>=1.07524767905\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:45 INFO 139969969338176] #quality_metric: host=algo-1, epoch=4, train mse <loss>=1.15615757131\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:45 INFO 139969969338176] #quality_metric: host=algo-1, epoch=4, train absolute_loss <loss>=0.890382076054\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 543.2898998260498, \"sum\": 543.2898998260498, \"min\": 543.2898998260498}}, \"EndTime\": 1606781085.625989, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1606781085.08202}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:45 INFO 139969969338176] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 456, \"sum\": 456.0, \"min\": 456}, \"Total Records Seen\": {\"count\": 1, \"max\": 453850, \"sum\": 453850.0, \"min\": 453850}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}}, \"EndTime\": 1606781085.626178, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 4}, \"StartTime\": 1606781085.082671}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:45 INFO 139969969338176] #throughput_metric: host=algo-1, train throughput=166609.334643 records/second\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:45 INFO 139969969338176] #quality_metric: host=algo-1, epoch=5, batch=0 train rmse <loss>=1.02531358342\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:45 INFO 139969969338176] #quality_metric: host=algo-1, epoch=5, batch=0 train mse <loss>=1.05126794434\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:45 INFO 139969969338176] #quality_metric: host=algo-1, epoch=5, batch=0 train absolute_loss <loss>=0.855046020508\u001b[0m\n",
      "\u001b[34m[2020-12-01 00:04:46.106] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 12, \"duration\": 478, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:46 INFO 139969969338176] #quality_metric: host=algo-1, epoch=5, train rmse <loss>=1.05703627386\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:46 INFO 139969969338176] #quality_metric: host=algo-1, epoch=5, train mse <loss>=1.11732568426\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:46 INFO 139969969338176] #quality_metric: host=algo-1, epoch=5, train absolute_loss <loss>=0.869958960229\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 479.7980785369873, \"sum\": 479.7980785369873, \"min\": 479.7980785369873}}, \"EndTime\": 1606781086.106448, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1606781085.626053}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:46 INFO 139969969338176] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 547, \"sum\": 547.0, \"min\": 547}, \"Total Records Seen\": {\"count\": 1, \"max\": 544420, \"sum\": 544420.0, \"min\": 544420}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 7, \"sum\": 7.0, \"min\": 7}}, \"EndTime\": 1606781086.106595, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 5}, \"StartTime\": 1606781085.626625}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:46 INFO 139969969338176] #throughput_metric: host=algo-1, train throughput=188664.627084 records/second\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:46 INFO 139969969338176] #quality_metric: host=algo-1, epoch=6, batch=0 train rmse <loss>=1.00781295422\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:46 INFO 139969969338176] #quality_metric: host=algo-1, epoch=6, batch=0 train mse <loss>=1.01568695068\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:46 INFO 139969969338176] #quality_metric: host=algo-1, epoch=6, batch=0 train absolute_loss <loss>=0.836027954102\u001b[0m\n",
      "\u001b[34m[2020-12-01 00:04:46.620] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 14, \"duration\": 512, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:46 INFO 139969969338176] #quality_metric: host=algo-1, epoch=6, train rmse <loss>=1.04045452798\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:46 INFO 139969969338176] #quality_metric: host=algo-1, epoch=6, train mse <loss>=1.08254562479\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:46 INFO 139969969338176] #quality_metric: host=algo-1, epoch=6, train absolute_loss <loss>=0.850471241039\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 514.106035232544, \"sum\": 514.106035232544, \"min\": 514.106035232544}}, \"EndTime\": 1606781086.621168, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1606781086.106508}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:46 INFO 139969969338176] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 638, \"sum\": 638.0, \"min\": 638}, \"Total Records Seen\": {\"count\": 1, \"max\": 634990, \"sum\": 634990.0, \"min\": 634990}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 8, \"sum\": 8.0, \"min\": 8}}, \"EndTime\": 1606781086.62132, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 6}, \"StartTime\": 1606781086.107037}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:46 INFO 139969969338176] #throughput_metric: host=algo-1, train throughput=176079.406366 records/second\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:46 INFO 139969969338176] #quality_metric: host=algo-1, epoch=7, batch=0 train rmse <loss>=0.99217851866\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:46 INFO 139969969338176] #quality_metric: host=algo-1, epoch=7, batch=0 train mse <loss>=0.984418212891\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:46 INFO 139969969338176] #quality_metric: host=algo-1, epoch=7, batch=0 train absolute_loss <loss>=0.818068786621\u001b[0m\n",
      "\u001b[34m[2020-12-01 00:04:47.158] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 16, \"duration\": 535, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:47 INFO 139969969338176] #quality_metric: host=algo-1, epoch=7, train rmse <loss>=1.02575890152\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:47 INFO 139969969338176] #quality_metric: host=algo-1, epoch=7, train mse <loss>=1.05218132405\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:47 INFO 139969969338176] #quality_metric: host=algo-1, epoch=7, train absolute_loss <loss>=0.833029826741\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 536.8349552154541, \"sum\": 536.8349552154541, \"min\": 536.8349552154541}}, \"EndTime\": 1606781087.158616, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1606781086.62123}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:47 INFO 139969969338176] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 729, \"sum\": 729.0, \"min\": 729}, \"Total Records Seen\": {\"count\": 1, \"max\": 725560, \"sum\": 725560.0, \"min\": 725560}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}}, \"EndTime\": 1606781087.158761, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 7}, \"StartTime\": 1606781086.621758}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:47 INFO 139969969338176] #throughput_metric: host=algo-1, train throughput=168632.507899 records/second\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:47 INFO 139969969338176] #quality_metric: host=algo-1, epoch=8, batch=0 train rmse <loss>=0.978507874845\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:47 INFO 139969969338176] #quality_metric: host=algo-1, epoch=8, batch=0 train mse <loss>=0.957477661133\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:47 INFO 139969969338176] #quality_metric: host=algo-1, epoch=8, batch=0 train absolute_loss <loss>=0.802256286621\u001b[0m\n",
      "\u001b[34m[2020-12-01 00:04:47.657] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 18, \"duration\": 497, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:47 INFO 139969969338176] #quality_metric: host=algo-1, epoch=8, train rmse <loss>=1.01298207936\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:47 INFO 139969969338176] #quality_metric: host=algo-1, epoch=8, train mse <loss>=1.02613269311\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:47 INFO 139969969338176] #quality_metric: host=algo-1, epoch=8, train absolute_loss <loss>=0.818184716529\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 498.95787239074707, \"sum\": 498.95787239074707, \"min\": 498.95787239074707}}, \"EndTime\": 1606781087.658222, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1606781087.158675}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:47 INFO 139969969338176] #progress_metric: host=algo-1, completed 90 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 820, \"sum\": 820.0, \"min\": 820}, \"Total Records Seen\": {\"count\": 1, \"max\": 816130, \"sum\": 816130.0, \"min\": 816130}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}}, \"EndTime\": 1606781087.658376, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 8}, \"StartTime\": 1606781087.159238}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:47 INFO 139969969338176] #throughput_metric: host=algo-1, train throughput=181421.931913 records/second\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:47 INFO 139969969338176] #quality_metric: host=algo-1, epoch=9, batch=0 train rmse <loss>=0.966733126055\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:47 INFO 139969969338176] #quality_metric: host=algo-1, epoch=9, batch=0 train mse <loss>=0.934572937012\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:47 INFO 139969969338176] #quality_metric: host=algo-1, epoch=9, batch=0 train absolute_loss <loss>=0.78880645752\u001b[0m\n",
      "\u001b[34m[2020-12-01 00:04:48.163] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 20, \"duration\": 503, \"num_examples\": 91, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:48 INFO 139969969338176] #quality_metric: host=algo-1, epoch=9, train rmse <loss>=1.00201700881\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:48 INFO 139969969338176] #quality_metric: host=algo-1, epoch=9, train mse <loss>=1.00403808594\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:48 INFO 139969969338176] #quality_metric: host=algo-1, epoch=9, train absolute_loss <loss>=0.805990400713\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:48 INFO 139969969338176] #quality_metric: host=algo-1, train rmse <loss>=1.00201700881\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:48 INFO 139969969338176] #quality_metric: host=algo-1, train mse <loss>=1.00403808594\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:48 INFO 139969969338176] #quality_metric: host=algo-1, train absolute_loss <loss>=0.805990400713\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 505.71608543395996, \"sum\": 505.71608543395996, \"min\": 505.71608543395996}}, \"EndTime\": 1606781088.164565, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1606781087.658283}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:48 INFO 139969969338176] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 911, \"sum\": 911.0, \"min\": 911}, \"Total Records Seen\": {\"count\": 1, \"max\": 906700, \"sum\": 906700.0, \"min\": 906700}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 11, \"sum\": 11.0, \"min\": 11}}, \"EndTime\": 1606781088.164775, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 9}, \"StartTime\": 1606781087.658822}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:48 INFO 139969969338176] #throughput_metric: host=algo-1, train throughput=178969.817552 records/second\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:48 WARNING 139969969338176] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:48 INFO 139969969338176] Pulling entire model from kvstore to finalize\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 1.795053482055664, \"sum\": 1.795053482055664, \"min\": 1.795053482055664}}, \"EndTime\": 1606781088.166862, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1606781088.164633}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:48 INFO 139969969338176] Saved checkpoint to \"/tmp/tmpJ3U8Vg/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[2020-12-01 00:04:48.172] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 0, \"duration\": 5590, \"num_examples\": 1, \"num_bytes\": 64000}\u001b[0m\n",
      "\u001b[34m[2020-12-01 00:04:48.202] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 1, \"duration\": 29, \"num_examples\": 10, \"num_bytes\": 603520}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 9430, \"sum\": 9430.0, \"min\": 9430}, \"Total Batches Seen\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}, \"Total Records Seen\": {\"count\": 1, \"max\": 9430, \"sum\": 9430.0, \"min\": 9430}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 9430, \"sum\": 9430.0, \"min\": 9430}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1606781088.202834, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"test_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1606781088.172755}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:48 INFO 139969969338176] #test_score (algo-1) : ('rmse', 1.0177643637052611)\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:48 INFO 139969969338176] #test_score (algo-1) : ('mse', 1.0358443000283752)\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:48 INFO 139969969338176] #test_score (algo-1) : ('absolute_loss', 0.835795895848522)\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:48 INFO 139969969338176] #quality_metric: host=algo-1, test rmse <loss>=1.01776436371\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:48 INFO 139969969338176] #quality_metric: host=algo-1, test mse <loss>=1.03584430003\u001b[0m\n",
      "\u001b[34m[12/01/2020 00:04:48 INFO 139969969338176] #quality_metric: host=algo-1, test absolute_loss <loss>=0.835795895849\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 5672.15895652771, \"sum\": 5672.15895652771, \"min\": 5672.15895652771}, \"setuptime\": {\"count\": 1, \"max\": 42.443037033081055, \"sum\": 42.443037033081055, \"min\": 42.443037033081055}}, \"EndTime\": 1606781088.203549, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1606781088.16693}\n",
      "\u001b[0m\n",
      "\n",
      "2020-12-01 00:04:59 Uploading - Uploading generated training model\n",
      "2020-12-01 00:04:59 Completed - Training job completed\n",
      "Training seconds: 57\n",
      "Billable seconds: 57\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import image_uris\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "#Find the name of the factorization machines container, configure the estimator function and hyperparameters\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "#define algorythm to use in container\n",
    "container = image_uris.retrieve('factorization-machines', region)\n",
    "role =  sagemaker.get_execution_role()\n",
    "\n",
    "\n",
    "fm = sagemaker.estimator.Estimator(container,\n",
    "                                   role, \n",
    "                                   instance_count=1, \n",
    "                                   instance_type='ml.c5.xlarge',\n",
    "                                   output_path=output_prefix,\n",
    "                                   sagemaker_session=sess)\n",
    "#required hyperparameters\n",
    "fm.set_hyperparameters(feature_dim= num_features,\n",
    "                      predictor_type='regressor',\n",
    "                      mini_batch_size=1000,\n",
    "                      num_factors=64,\n",
    "                      epochs=10)\n",
    "#launch the training job\n",
    "fm.fit({'train': train_data, 'test':test_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "\n",
    "#Create endpoint for inferance\n",
    "endpoint_name = 'fm-movielens-100k'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------!"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "#This appears to be due to the removal of the methods in version 2.x of the SageMaker.  Fix bug below.\n",
    "class FMSerializer(JSONSerializer):\n",
    "    def serialize(self, data):\n",
    "       js = {'instances': []}\n",
    "       for row in data:\n",
    "              js['instances'].append({'features': row.tolist()})\n",
    "       return json.dumps(js)\n",
    "\n",
    "\n",
    "\n",
    "fm_predictor = fm.deploy(endpoint_name = endpoint_name,\n",
    "                         initial_instance_count=1,\n",
    "                         instance_type='ml.t2.medium',\n",
    "                         serializer=FMSerializer(),\n",
    "                         deserializer= JSONDeserializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [{'score': 3.384589433670044}, {'score': 3.4442405700683594}, {'score': 3.6831166744232178}]}\n"
     ]
    }
   ],
   "source": [
    "#Send the first of the test set for prediction\n",
    "result = fm_predictor.predict(X_test[:3].toarray())\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete endpoint\n",
    "\n",
    "fm_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "from sagemaker import image_uris\n",
    "\n",
    "num_users = 945\n",
    "num_movies = 1682\n",
    "num_features = num_users + num_movies\n",
    "num_ratings_train = 90570\n",
    "num_ratings_test = 9430\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "#Find the name of the factorization machines container, configure the estimator function and hyperparameters\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "#define algorythm to use in container\n",
    "container = image_uris.retrieve('pca', region)\n",
    "role =  sagemaker.get_execution_role()\n",
    "\n",
    "\n",
    "pca = sagemaker.estimator.Estimator(container,\n",
    "                                   role, \n",
    "                                   instance_count=1, \n",
    "                                   instance_type='ml.c5.xlarge',\n",
    "                                   output_path=output_prefix\n",
    "                                   )\n",
    "#required hyperparameters\n",
    "pca.set_hyperparameters(feature_dim= num_features,\n",
    "                      num_components = 64,\n",
    "                      mini_batch_size=1024,\n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-01 02:18:40 Starting - Starting the training job...\n",
      "2020-12-01 02:18:42 Starting - Launching requested ML instances......\n",
      "2020-12-01 02:19:57 Starting - Preparing the instances for training.........\n",
      "2020-12-01 02:21:32 Downloading - Downloading input data\n",
      "2020-12-01 02:21:32 Training - Downloading the training image..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[12/01/2020 02:21:49 INFO 140040044738368] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-conf.json: {u'_num_gpus': u'auto', u'_log_level': u'info', u'subtract_mean': u'true', u'force_dense': u'true', u'epochs': 1, u'algorithm_mode': u'regular', u'extra_components': u'-1', u'_kvstore': u'dist_sync', u'_num_kv_servers': u'auto'}\u001b[0m\n",
      "\u001b[34m[12/01/2020 02:21:49 INFO 140040044738368] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'2627', u'mini_batch_size': u'1024', u'num_components': u'64'}\u001b[0m\n",
      "\u001b[34m[12/01/2020 02:21:49 INFO 140040044738368] Final configuration: {u'num_components': u'64', u'_num_gpus': u'auto', u'_log_level': u'info', u'subtract_mean': u'true', u'force_dense': u'true', u'epochs': 1, u'algorithm_mode': u'regular', u'feature_dim': u'2627', u'extra_components': u'-1', u'_kvstore': u'dist_sync', u'_num_kv_servers': u'auto', u'mini_batch_size': u'1024'}\u001b[0m\n",
      "\u001b[34m[12/01/2020 02:21:49 WARNING 140040044738368] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[12/01/2020 02:21:49 INFO 140040044738368] Launching parameter server for role scheduler\u001b[0m\n",
      "\u001b[34m[12/01/2020 02:21:49 INFO 140040044738368] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/1ebab356-2d23-49ca-952a-6814e042d446', 'ECS_CONTAINER_METADATA_URI_V4': 'http://169.254.170.2/v4/1ebab356-2d23-49ca-952a-6814e042d446', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'AWS_REGION': 'us-east-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-12-01-02-18-40-221', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '2', 'HOSTNAME': 'ip-10-0-211-89.ec2.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/a3395446-666c-4f40-8eb1-a4a2e31a05db', 'PWD': '/', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:027893685092:training-job/pca-2020-12-01-02-18-40-221', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[12/01/2020 02:21:49 INFO 140040044738368] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/1ebab356-2d23-49ca-952a-6814e042d446', 'ECS_CONTAINER_METADATA_URI_V4': 'http://169.254.170.2/v4/1ebab356-2d23-49ca-952a-6814e042d446', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '1', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.211.89', 'AWS_REGION': 'us-east-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-12-01-02-18-40-221', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '2', 'HOSTNAME': 'ip-10-0-211-89.ec2.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/a3395446-666c-4f40-8eb1-a4a2e31a05db', 'DMLC_ROLE': 'scheduler', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:027893685092:training-job/pca-2020-12-01-02-18-40-221', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[12/01/2020 02:21:49 INFO 140040044738368] Launching parameter server for role server\u001b[0m\n",
      "\u001b[34m[12/01/2020 02:21:49 INFO 140040044738368] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/1ebab356-2d23-49ca-952a-6814e042d446', 'ECS_CONTAINER_METADATA_URI_V4': 'http://169.254.170.2/v4/1ebab356-2d23-49ca-952a-6814e042d446', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'AWS_REGION': 'us-east-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-12-01-02-18-40-221', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '2', 'HOSTNAME': 'ip-10-0-211-89.ec2.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/a3395446-666c-4f40-8eb1-a4a2e31a05db', 'PWD': '/', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:027893685092:training-job/pca-2020-12-01-02-18-40-221', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[12/01/2020 02:21:49 INFO 140040044738368] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/1ebab356-2d23-49ca-952a-6814e042d446', 'ECS_CONTAINER_METADATA_URI_V4': 'http://169.254.170.2/v4/1ebab356-2d23-49ca-952a-6814e042d446', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '1', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.211.89', 'AWS_REGION': 'us-east-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-12-01-02-18-40-221', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '2', 'HOSTNAME': 'ip-10-0-211-89.ec2.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/a3395446-666c-4f40-8eb1-a4a2e31a05db', 'DMLC_ROLE': 'server', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:027893685092:training-job/pca-2020-12-01-02-18-40-221', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[12/01/2020 02:21:49 INFO 140040044738368] Environment: {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/1ebab356-2d23-49ca-952a-6814e042d446', 'ECS_CONTAINER_METADATA_URI_V4': 'http://169.254.170.2/v4/1ebab356-2d23-49ca-952a-6814e042d446', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_WORKER': '1', 'SAGEMAKER_HTTP_PORT': '8080', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.211.89', 'AWS_REGION': 'us-east-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-12-01-02-18-40-221', 'HOME': '/root', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '2', 'HOSTNAME': 'ip-10-0-211-89.ec2.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/a3395446-666c-4f40-8eb1-a4a2e31a05db', 'DMLC_ROLE': 'worker', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:027893685092:training-job/pca-2020-12-01-02-18-40-221', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34mProcess 61 is a shell:scheduler.\u001b[0m\n",
      "\u001b[34mProcess 70 is a shell:server.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[12/01/2020 02:21:49 INFO 140040044738368] Using default worker.\u001b[0m\n",
      "\u001b[34m[12/01/2020 02:21:49 INFO 140040044738368] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[12/01/2020 02:21:49 INFO 140040044738368] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[12/01/2020 02:21:49 INFO 140040044738368] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[12/01/2020 02:21:50 INFO 140040044738368] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[2020-12-01 02:21:50.028] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[34m[12/01/2020 02:21:50 INFO 140040044738368] Create Store: dist_sync\u001b[0m\n",
      "\u001b[34m[12/01/2020 02:21:50 INFO 140040044738368] nvidia-smi took: 0.0251550674438 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[12/01/2020 02:21:50 INFO 140040044738368] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[12/01/2020 02:21:50 INFO 140040044738368] The default executor is <PCAExecutor on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[12/01/2020 02:21:50 INFO 140040044738368] 2627 feature(s) found in 'data'.\u001b[0m\n",
      "\u001b[34m[12/01/2020 02:21:50 INFO 140040044738368] <PCAExecutor on cpu(0)> is assigned to batch slice from 0 to 1023.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 599.1818904876709, \"sum\": 599.1818904876709, \"min\": 599.1818904876709}}, \"EndTime\": 1606789310.641326, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1606789310.014492}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1606789310.641522, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1606789310.641476}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-12-01 02:21:50.647] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 631, \"num_examples\": 1, \"num_bytes\": 65536}\u001b[0m\n",
      "\n",
      "2020-12-01 02:22:09 Uploading - Uploading generated training model\n",
      "2020-12-01 02:22:09 Completed - Training job completed\n",
      "\u001b[34m[2020-12-01 02:21:56.902] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 6232, \"num_examples\": 89, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"update.time\": {\"count\": 1, \"max\": 6256.025075912476, \"sum\": 6256.025075912476, \"min\": 6256.025075912476}}, \"EndTime\": 1606789316.90319, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1606789310.641415}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/01/2020 02:21:56 INFO 140040044738368] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 89, \"sum\": 89.0, \"min\": 89}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 89, \"sum\": 89.0, \"min\": 89}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 89, \"sum\": 89.0, \"min\": 89}, \"Total Records Seen\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1606789316.903886, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"PCA\", \"epoch\": 0}, \"StartTime\": 1606789310.647124}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/01/2020 02:21:56 INFO 140040044738368] #throughput_metric: host=algo-1, train throughput=14474.8656389 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 4366.436004638672, \"sum\": 4366.436004638672, \"min\": 4366.436004638672}}, \"EndTime\": 1606789321.270939, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1606789316.90347}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/01/2020 02:22:01 INFO 140040044738368] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[2020-12-01 02:22:01.279] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 0, \"duration\": 11250, \"num_examples\": 1, \"num_bytes\": 65536}\u001b[0m\n",
      "\u001b[34m[12/01/2020 02:22:01 INFO 140040044738368] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[12/01/2020 02:22:01 INFO 140040044738368] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1023.\u001b[0m\n",
      "\u001b[34m[2020-12-01 02:22:01.598] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 1, \"duration\": 318, \"num_examples\": 10, \"num_bytes\": 603520}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 9430, \"sum\": 9430.0, \"min\": 9430}, \"Total Batches Seen\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}, \"Total Records Seen\": {\"count\": 1, \"max\": 9430, \"sum\": 9430.0, \"min\": 9430}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 9430, \"sum\": 9430.0, \"min\": 9430}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1606789321.599008, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"test_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1606789321.276569}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/01/2020 02:22:01 INFO 140040044738368] #test_score (algo-1) : ('pln', 0.9113882138255895)\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 11724.040985107422, \"sum\": 11724.040985107422, \"min\": 11724.040985107422}, \"setuptime\": {\"count\": 1, \"max\": 17.616987228393555, \"sum\": 17.616987228393555, \"min\": 17.616987228393555}}, \"EndTime\": 1606789321.605897, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1606789321.271001}\n",
      "\u001b[0m\n",
      "Training seconds: 54\n",
      "Billable seconds: 54\n"
     ]
    }
   ],
   "source": [
    "#launch the training job\n",
    "pca.fit({'train': train_data, 'test':test_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "#This appears to be due to the removal of the methods in version 2.x of the SageMaker.  Fix bug below.\n",
    "class FMSerializer(JSONSerializer):\n",
    "    def serialize(self, data):\n",
    "       js = {'instances': []}\n",
    "       for row in data:\n",
    "              js['instances'].append({'features': row.tolist()})\n",
    "       return json.dumps(js)\n",
    "\n",
    "\n",
    "pca_predictor = pca.deploy(endpoint_name = 'pca-movielens-100k',\n",
    "                         initial_instance_count=1,\n",
    "                         instance_type='ml.t2.medium',\n",
    "                          serializer=FMSerializer(),\n",
    "                         deserializer= JSONDeserializer())\n",
    "\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Send the first of the test set for prediction\n",
    "result = pca_predictor.predict(X_test[:0].toarray())\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete endpoint\n",
    "\n",
    "pca_predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
